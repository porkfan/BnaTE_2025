# 1. Graph-pangenome analysis

## 1.1 Graph-pangenome construct

We constructed a graph pangenome of 14 Brassica napus genomes using minigraph-cactus pipeline, with ZS11 reference genome as the backbone and 13 other assembled genomes.

```bash
seq=Brassica_napus14.seq
cpu=40

cactus-pangenome ./js $seq --outDir Brassica_napus14-pg --outName Brassica_napus14-pg --reference ZS11v0 --vcf --giraffe --gfa --gbz --maxCores $cpu --permissiveContigFilter
```

## 1.2 Graph Pangenome Growth Curve

Using panacus to plot the growth curve of the graph pangenome based on the gfa file generated by minigraph-cactus

```bash
panacus ordered-histgrowth -c bp -t20 -l 1,2,4,12 -S -O mc_Brassica_napus14-pg.order.samples.txt -e mc_Brassica_napus14pg.walks_ref.txt mc_Brassica_napus14-pg.gfa
panacus ordered-histgrowth -c node -t20 -l 1,2,4,12 -S -O mc_Brassica_napus14-pg.order.samples.txt -e mc_Brassica_napus14pg.walks_ref.txt mc_Brassica_napus14-pg.gfa
panacus ordered-histgrowth -c edge -t20 -l 1,2,4,12 -S -O mc_Brassica_napus14-pg.order.samples.txt -e mc_Brassica_napus14pg.walks_ref.txt mc_Brassica_napus14-pg.gfa
```
# 2. Determination of the structural variant (SV) set in the graph-pangenome and genotyping SV in 2311 accessions

## 2.1 Determination of the structural variant (SV) set in the graph-pangenome

Remove bubbles larger than 100kb from raw.vcf using vcfbub

```bash
vcfbub -r 100000 Brassica_napus14-pg.raw.vcf > Brassica_napus14-pg.raw_r100kb.vcf
```

Keep only non-overlapping bubbles with minimum LV using script

```bash
python filter_outmost_bubble.py Brassica_napus14-pg.raw_r100kb.vcf Brassica_napus14-pg.raw_r100kb_fil.vcf
```

After a series of filtering steps to obtain the graph-genome SV set for PanGenie index construction

```bash
### Filter variants with too many missing values
python filter_missing.py Brassica_napus14-pg.raw_r100kb_fil.vcf Brassica_napus14-pg.raw_r100kb_fil_0.5missing.vcf 4
### Convert all genotypes to homozygous format (1->1|1, .->.|., 0->0|0, N->N|N)
python phase.py
### Remove sequences containing N in variants
python delete_N.py
### Remove alternative alleles not covered by any haplotype
bcftools view --trim-alt-alleles Brassica_napus14-pg.raw_r100kb_fil_0.5missing_phased_deleteN > Brassica_napus14-pg.raw_r100kb_fil_0.5missing_phased_deleteN_trim.vcf
### Decompose and annotate bubbles using annotate_vcf.py
python annotate_vcf.py -vcf Brassica_napus14-pg.raw_r100kb_fil_0.5missing_phased_deleteN_trim.vcf -gfa Brassica_napus14-pg.gfa  -o Brassica_napus14-pg.raw_r100kb_fil_0.5missing_phased_deleteN_trim_id
### Filter rows where alt column is '.' using filter_vcf.py
python filter_vcf.py
Brassica_napus14-pg.raw_r100kb_fil_0.5missing_phased_deleteN_id_trim.vcf -> Brassica_napus14-pg.raw_r100kb_fil_0.5missing_phased_deleteN_trim_id_filter.vcf
### Extract variants >50bp (includes some <50bp variants in multi-allelic cases with SVs)
python keep_sv_vcf.py  Brassica_napus14-pg.raw_r100kb_fil_0.5missing_phased_deleteN_trim_id_filter.vcf  Brassica_napus14-pg.raw_r100kb_fil_0.5missing_phased_deleteN_trim_id_filter_SV.vcf
```

## 2.2 Build the graph-genome index by PanGenie

Create PanGenie index

```bash
module load Singularity/3.7.3
singularity exec pangenie.sif  PanGenie-index -v  Brassica_napus14-pg.raw_r100kb_fil_0.5missing_phased_deleteN_trim_id_filter_SV.vcf  -r Brassica_napus.ZS11.v0.genome.fa  -t 20 -o PanGenie
```

## 2.3 SV genotyping in 2311 accessions

Use PanGenie to perform SV genotyping on second-generation reads data from 2311 populations

```bash
cat sample_2311.txt|while read sample;do
bsub -J PanGenie_${sample} -q normal -n 4 -R span[hosts=1] -o genotype_log/${sample}.out -e genotype_log/${sample}.err "sh PanGenie.sh ${sample}"
done

tmp_dir="tmp" # Temporary directory
output_dir="2311pop_pangenie" # Output directory

# Create temporary directory
mkdir -p ${tmp_dir}
mkdir -p ${output_dir}

# Merge paired-end data and decompress to fq file
zcat ${input_dir}/${sample}_1_clean.fq.gz  ${input_dir}/${sample}_2_clean.fq.gz > ${tmp_dir}/${sample}.fq

# Execute PanGenie
PanGenie -f PanGenie -i ${tmp_dir}/${sample}.fq -o ${output_dir}/${sample} -s ${sample} -j 4 -t 4

# Remove temporary fq file after completion
rm ${tmp_dir}/${sample}.fq
```

## 2.4 convert-to-biallelic

Use the convert-to-biallelic.py script provided by the PanGenie pipeline to convert multi-allelic variants to bi-allelic after genotyping
convert-to-biallelic.py

```bash
cat 2311pop_pangenie/${sample}_genotyping.vcf |python3 convert-to-biallelic.py  Brassica_napus14-pg.raw_r100kb_fil_0.5missing_phased_deleteN_trim_id_biallelic.vcf  > 2311pop_pangenie/${sample}_genotyping_biallelic.vcf
```
# 3. TE-annote

## 3.1 TE annote in 14 genomes by EDTA

Use EDTA to annotate 14 genomes and generate individual TElib for each genome

```bash
EDTA.pl --genome Brassica_napus.${genome}.genome.fa --species others --anno 1 --sensitive 1  --step all --t 40 --cds Brassica_napus.${genome}.cds.fa
```

## 3.2 panEDTA pipeline build a panTElib in 14 genomes

Use panEDTA pipeline to generate a non-redundant panTElib based on the individual TElibs from 14 genomes generated by EDTA

```bash
sh panEDTA.sh -g genome_list.txt  -c Brassica_napus.ZS11.v0.cds.fa  -t 40
```

## 3.3 repeatmasker 14genomes by panTElib

Re-annotate 14 genomes using repeatmasker based on the generated panTElib to create individual panTE annotations

```bash
cat genome_list|while read sample;do
bsub -J ${sample}_RM -q normal -n 10 -R span[hosts=1] -o log/${sample}_RM.out -e log/${sample}_RM.err \
"RepeatMasker -e ncbi -pa 20 -q -div 40 -lib genome_list.txt.panEDTA.TElib.fa  -cutoff 225 -gff Brassica_napus.${sample}.genome.fa"
done
```
# 4. Obtain TE genotypes for the graph pangenome and 2311 populations using SV genotypes from 2311 populations and TE annotations from each genome in the graph

## 4.1 Use halLiftover to perform coordinate conversion based on the graph pangenome's hal file

```bash
singularity exec cactus_v2.6.8.sif halLiftover Brassica_napus14-pg.full.hal ${genome_1} ${bed_1} ${genome_2} ${bed_2}
```

## 4.2 Convert SV genotypes to corresponding TE genotypes based on the overlap between population SV and TE annotation information

```bash
python TE_SV_overlap.py
```
# 5. RNA-seq

## 5.1 Quality Control

Use TrimGalore for quality control and adapter trimming of transcriptome data

```bash
# 01_TrimGalore.sh
module load TrimGalore/0.6.6
sample=$1
trim_galore --paired --quality 20 -a AGATCGGAAGAGC -a2 AGATCGGAAGAGC --length 20 -o 01_trim/20DAF_seed/  raw_data/20DAF_seed/${sample}_1.fq.gz raw_data/20DAF_seed/${sample}_2.fq.gz
```

## 5.2 Alignment

Align quality-controlled fastq files to the reference genome using STAR

```bash
#02_star.sh
module load STAR/2.7.8a
module load SAMtools/1.9
sample=$1
mkdir -p star/${sample}
#Alignment
STAR --runThreadN 4 --genomeDir ref  --twopassMode Basic --readFilesCommand zcat --readFilesIn 01_trim/20DAF_seed/${sample}_1_val_1.fq.gz  01_trim/20DAF_seed/${sample}_2_val_2.fq.gz  --outFileNamePrefix star/${sample}/${sample} --outSAMtype BAM SortedByCoordinate --outBAMsortingThreadN 4 --quantMode  GeneCounts
samtools index star/${sample}/${sample}Aligned.sortedByCoord.out.bam
```

## 5.3 TMM Normalization

Perform TMM normalization to generate population transcriptome data for subsequent eQTL analysis

```R
library(edgeR)
data=read.table("read_counts_filter.txt", header = TRUE)
# Extract sample columns
gene_info <- data[, 1:6] # First six columns are gene information
counts_matrix <- data[, 7:ncol(data)]
# Create DGEList object
dge <- DGEList(counts = counts_matrix)
# Perform TMM normalization
dge <- calcNormFactors(dge)
# View normalized data
normalized_counts <- cpm(dge, log = TRUE)
# Merge gene information with normalized data
normalized_data <- cbind(gene_info, normalized_counts)
write.table(normalized_data, "result_TMM.txt", sep = "\t", row=F,col=T,quo=F)
```
# 6. TE-GWAS

Generate kinship matrix and PCA results

```bash
module load gcta/1.94.1
module load gemma/0.98.5

f=${phenotype}
gcta --bfile $f --autosome --make-grm --out $f
gcta --grm $f --pca 10 --out $f_pca10
awk '{print "1\t"$3"\t"$4"\t"$5}' ${f}_pca10.eigenvec > ${f}_pca3_cov.txt
cut -f2 ${f}_pca3_cov.txt > tmp.txt
gemma -bfile ${f} -gk 2 -o ${f} -p tmp.txt
```

Perform GWAS using GEMMA and GCTA

```bash
module load gcta/1.94.1
module load gemma/0.98.5
i=$1
cpu=4
f=${phenotype}
grm=${phenotype}
q=${phenotype}_pca10.eigenvec

gcta --mlma --bfile $f --grm $grm --pheno ${i}.txt --qcovar $q --out GCTA_out/${i}_gcta --thread-num $cpu

mkdir -p gemma_output/${i}

cd gemma_output/${i}
awk -F '\t' '{print $3}' /${i}.txt > ${i}.phe.tmp
gemma -bfile $f -gk 2 -p ${i}.phe.tmp -o ${i}
gemma -bfile $f -k output/${i}.sXX.txt -p ${i}.phe.tmp -lmm 1 -c $q -o ${i}_gemma

```
# 7. TE-eQTL

## 7.1 TE-cis-eQTL

Perform cis-eQTL analysis using the cis parameter in QTLtools

```bash
QTLtools cis --vcf arabidopsis.impute.maf0.05.mis0.5.recode.vcf.gz --bed Bna_TMM.bed.gz --cov PCA_top_10.pca.gz --nominal 1 --window 1000000 --std-err --out 02.nominal/cis.nominal
```

## 7.2 TE-trans-eQTL

Perform trans-eQTL analysis using the trans parameter in QTLtools

```bash
QTLtools trans --vcf arabidopsis_impute_maf0.05.het0.5.recode.vcf.gz --bed Bna_TMM.bed.gz --cov PCA_10.pca.gz --nominal --threshold ${threshold} --window 1000000  --out 02.result/trans.nominal
```
# 8. TE-Gene

Obtain the nearest TE for each Gene

```bash
python get_Gene_closest_TE.py
```
